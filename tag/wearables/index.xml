<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>wearables | Peter Charlton</title>
    <link>https://peterhcharlton.github.io/tag/wearables/</link>
      <atom:link href="https://peterhcharlton.github.io/tag/wearables/index.xml" rel="self" type="application/rss+xml" />
    <description>wearables</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2021 Peter Charlton</copyright><lastBuildDate>Tue, 02 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://peterhcharlton.github.io/media/icon_hu5d370b2f3224e8711b194d151b733caa_16531_512x512_fill_lanczos_center_2.png</url>
      <title>wearables</title>
      <link>https://peterhcharlton.github.io/tag/wearables/</link>
    </image>
    
    <item>
      <title>Photoplethysmography Datasets</title>
      <link>https://peterhcharlton.github.io/post/ppg_datasets/</link>
      <pubDate>Tue, 02 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/post/ppg_datasets/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This table provides a list of publicly available datasets containing photoplethysmogram signals. Further details are available in: &lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_review/&#34;&gt;Wearable Photoplethysmography for Cardiovascular Monitoring&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dataset&lt;/th&gt;
&lt;th&gt;Ref&lt;/th&gt;
&lt;th&gt;No. subjs&lt;/th&gt;
&lt;th&gt;Other signals&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.ukbiobank.ac.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UK Biobank&lt;/a&gt; (Field 4205)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;205,357&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Single finger PPG waves from middle-aged subjects.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://mimic.physionet.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIMIC Critical Care Database&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1038/sdata.2016.35&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;10,000s (growing)&lt;/td&gt;
&lt;td&gt;ECG, BP, resp, others&lt;/td&gt;
&lt;td&gt;Recordings from critically-ill adults and neonates, lasting from minutes to days. Typically at finger.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://vitaldb.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VitalDB&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1038/s41598-018-20062-4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;6,153&lt;/td&gt;
&lt;td&gt;ECG, BP, resp, others&lt;/td&gt;
&lt;td&gt;Finger PPG recordings from patients during operations.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://sleepdata.org/datasets/mesa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MESA Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5665/sleep.4732&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2,056&lt;/td&gt;
&lt;td&gt;ECG, resp, others&lt;/td&gt;
&lt;td&gt;Finger PPG recordings from adults undergoing polysomnography.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.6807402&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIMIC PERform Training and Testing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1088/1361-6579/ac826d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;400&lt;/td&gt;
&lt;td&gt;ECG, resp&lt;/td&gt;
&lt;td&gt;Recordings from critically-ill adults and neonates, lasting 10 minutes. Typically at finger.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SOMNIA Database&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1136/bmjopen-2019-030996&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;100s (growing)&lt;/td&gt;
&lt;td&gt;ECG, resp, others&lt;/td&gt;
&lt;td&gt;Wrist PPG recordings from children and adults undergoing polysomnography.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.6084/m9.figshare.5459299&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PPG-BP Database&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1038/sdata.2018.20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;219&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Three finger recordings from adults aged 20-89 with and without CVD, $\approx$ 3 waves per recording.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.6084/m9.figshare.1209662.v6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sleep Disordered Breathing Database&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1371/journal.pone.0112959&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;146&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Finger recordings lasting $\geq$ 3 hours, acquired from children referred for polysomnography.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.17632/vn5nknh3mn.2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ECSMP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1016/j.dib.2021.107660&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;ECG, accel, others&lt;/td&gt;
&lt;td&gt;Wrist recordings acquired from healthy subjects during a protocol designed to induce different emotions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.34973/te70-x603&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pulse transit time during vasoconstriction Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1016/j.exger.2020.110938&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;86&lt;/td&gt;
&lt;td&gt;ECG, BP&lt;/td&gt;
&lt;td&gt;$\approx$ 35-min wrist and finger recordings during cold pressor and active stand tests.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.18742/RDM01-194&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vortal Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1088/0967-3334/37/4/610&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;, &lt;a href=&#34;https://doi.org/10.1088/1361-6579/aa670e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;57&lt;/td&gt;
&lt;td&gt;ECG, resp&lt;/td&gt;
&lt;td&gt;10-min finger and ear recordings before and after exercise from healthy adults aged 18-39 and \textgreater 70.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.13026/C2208R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BIDMC&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1109/TBME.2016.2613124&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;53&lt;/td&gt;
&lt;td&gt;ECG, BP, resp&lt;/td&gt;
&lt;td&gt;8-min recordings from critically-ill adults (a subset of the MIMIC-II dataset).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;http://www.capnobase.org/index.php?id=857&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CapnoBase&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1109/TBME.2013.2246160&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;ECG, resp&lt;/td&gt;
&lt;td&gt;8-min recordings from paediatrics and adults during elective surgery and anaesthesia.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://dx.doi.org/10.21227/77hc-py84&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bed-based BCG Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.mdpi.com/1424-8220/21/1/156&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;ECG, BCG, BP&lt;/td&gt;
&lt;td&gt;Recordings from adults whilst at rest.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.6807402&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIMIC PERform AF Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1088/1361-6579/ac826d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;35&lt;/td&gt;
&lt;td&gt;ECG, resp&lt;/td&gt;
&lt;td&gt;Recordings from critically-ill adults categorised as either AF (19 subjects) or normal sinus rhythm (16 subjects), lasting 10 minutes. Typically at finger.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.17632/yynb8t9x3d.2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Real-World PPG dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.17632/yynb8t9x3d.2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;35&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Recordings from healthy subjects aged 10 to 74 years old: several 6-second recordings per subject.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.eecs.qmul.ac.uk/mmv/datasets/deap/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DEAP Database&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1109/T-AFFC.2011.15&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;ECG, resp, video, others&lt;/td&gt;
&lt;td&gt;Thumb recordings from young, healthy subjects whilst watching one-minute 40 videos.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/102.100.100/6914&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Queensland Vital Signs Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1213/ANE.0b013e318241f7c0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;ECG, resp, BP, EEG&lt;/td&gt;
&lt;td&gt;Recordings from patients during anaesthesia, ranging from minutes to hours in duration.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;http://esum.arch.ethz.ch/data&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESUM SNF Project Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1016/j.ins.2018.09.061&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;accel, EDA&lt;/td&gt;
&lt;td&gt;Wrist recordings whilst walking.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.3673924&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MARSH Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1016/j.bspc.2020.101887&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;29&lt;/td&gt;
&lt;td&gt;ECG, resp&lt;/td&gt;
&lt;td&gt;15-min finger recordings during spontaneous and metronome-guided breathing.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/mkachuee/noninvasivebp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Non-invasive BP Estimation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1109/TIM.2017.2745081&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;ECG, BP, PCG&lt;/td&gt;
&lt;td&gt;Finger recordings from healthy adults.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/hooseok/gyro_acc_ppg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gyro-acc-ppg Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1109/JSEN.2018.2879970&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;ECG, accel, gyro&lt;/td&gt;
&lt;td&gt;Wrist recordings from healthy subjects during an exercise protocol lasting 12 minutes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.13026/g3me-rt62&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pulse Transit Time PPG Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.13026/g3me-rt62&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;ECG, multiwavelength PPG&lt;/td&gt;
&lt;td&gt;Finger recordings from healthy subjects during sitting, walking and running.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/Welltory/welltory-ppg-dataset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Welltory-PPG-dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.3390/s21206798&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;RR intervals&lt;/td&gt;
&lt;td&gt;Smartphone recordings acquired from the index finger in contact with the camera.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.21979/N9/42BBFA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wearable and Clinical Devices Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.3390/s20236778&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;ECG, resp, accel, EDA&lt;/td&gt;
&lt;td&gt;Wrist PPG recordings acquired for 5 mins at rest, and 5mins whilst walking on spot.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/PPG-DaLiA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PPG-DaLiA Data Set&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.3390/s19143079&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;ECG, resp, accel, EDA&lt;/td&gt;
&lt;td&gt;Recordings acquired for $\approx$ 2.5 hours during a protocol of daily living activities.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/WESAD&amp;#43;%5c%28Wearable&amp;#43;Stress&amp;#43;and&amp;#43;Affect&amp;#43;Detection%5c%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WESAD Data Set&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1145/3242969.3242985&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;ECG, resp, accel, others&lt;/td&gt;
&lt;td&gt;Recordings acquired in a $\approx$ 2 hour protocol designed to amuse, stress, and relax.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.1012726&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;iAMwell Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;ECG, resp&lt;/td&gt;
&lt;td&gt;$\approx$ 20-min recordings before, during and after running.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.13026/chd5-t946&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simultaneous Measurements Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.cinc.org/archives/2019/pdf/CinC2019-031.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;ECG, accel, resp&lt;/td&gt;
&lt;td&gt;Recordings from adults at rest and during cognitive and physical tasks.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://sites.google.com/site/researchbyzhang/ieeespcup2015&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IEEE Signal Processing Cup 2015&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1109/TBME.2014.2359372&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;ECG, accel, two PPGs&lt;/td&gt;
&lt;td&gt;$\approx$ 5-min recordings during intensive physical exercise from males aged 18-35.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://affect.media.mit.edu/share-data.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AffectiveROAD Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1145/3167132.3167395&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;accel, EDA&lt;/td&gt;
&lt;td&gt;Recordings acquired whilst driving a car for $\approx$ 86 minutes from mostly young adults.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.4231/1BE9-YY17&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Labeled raw PPG Signals&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Finger recordings acquired at rest for $\approx$ 20-40 minutes from healthy adults.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.13026/C2PQ1X&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wrist PPG During Exercise&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.3390/data2010001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;ECG, gyro, accel&lt;/td&gt;
&lt;td&gt;Wrist recordings acquired from adults aged 22-32 during walking, running and bike riding.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1016/j.dib.2019.105044&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PPG-ACC Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1016/j.dib.2019.105044&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;accel&lt;/td&gt;
&lt;td&gt;Wrist recordings acquired from healthy adults aged 20-52 during rest, squatting and stepping.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.4231/8VF2-1729&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Raw PPG Signal in Varying Levels of Activity&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Finger recordings acquired at rest, talking and walking for $\approx$ 10 mins each from healthy adults.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.3268501&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PPG-Diary&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.3390/ecsa-7-08233&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;two PPGs&lt;/td&gt;
&lt;td&gt;A 28-day thumb recording from a healthy adult, with annotations of activities of daily living.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://affect.media.mit.edu/share-data.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eight-Emotion Sentics Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://affect.media.mit.edu/projectpages/archived/TR-526/TR-526.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;EMG, GSR, resp&lt;/td&gt;
&lt;td&gt;25-min recordings during a protocol to evoke emotions from 1 subject each day for 20 days.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.2633175&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pulse Wave DataBase&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1152/ajpheart.00218.2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4,374 (synthetic)&lt;/td&gt;
&lt;td&gt;BP, blood flow, others&lt;/td&gt;
&lt;td&gt;Single simulated PPG pulse waves representative of healthy adults aged 25-75.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.1296214&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Photoplethysmography in dogs and cats&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doi.org/10.1088/1361-6579/aaf433&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ref&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;21 (animals)&lt;/td&gt;
&lt;td&gt;three PPGs&lt;/td&gt;
&lt;td&gt;$\approx$ 10-20 sec recordings at several arterial sites from 11 dogs and 10 cats.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Defintions: resp - respiratory signal; PCG - phonocardiogram; accel - acceleromertry; gyro - gyroscope; EDA - electrodermal activity; EMG - electromyogram; GSR - galvanic skin response; ICP - intracranial pressure.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;p&gt;Original source (adapted under &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY 4.0&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P. H. Charlton &lt;em&gt;et al.&lt;/em&gt;, &amp;lsquo;Wearable Photoplethysmography for Cardiovascular Monitoring&amp;rsquo;, &lt;em&gt;Proceedings of the IEEE&lt;/em&gt;, vol.110(3), pp.355-381, 2022. DOI: &lt;a href=&#34;https://doi.org/10.1109/JPROC.2022.3149785&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.1109/JPROC.2022.3149785&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Version: 15 March 2022&lt;/p&gt;
&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;
&lt;p&gt;For further information on photoplethysmography, please see the following review paper: &lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_review/&#34;&gt;Wearable Photoplethysmography for Cardiovascular Monitoring&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting beats in the photoplethysmogram: benchmarking open-source algorithms</title>
      <link>https://peterhcharlton.github.io/publication/assess_ppg_beat_detectors/</link>
      <pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/assess_ppg_beat_detectors/</guid>
      <description>&lt;hr&gt;
&lt;h2 id=&#34;accompanying-resources&#34;&gt;Accompanying Resources&lt;/h2&gt;
&lt;p&gt;This study used two key resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;https://ppg-beats.readthedocs.io/en/latest/datasets/summary/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIMIC PERform&lt;/a&gt; datasets.&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;https://ppg-beats.readthedocs.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;lsquo;ppg-beats&amp;rsquo;&lt;/a&gt; toolbox of PPG beat detection algorithms and code to assess their performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reproducing-the-analysis&#34;&gt;Reproducing the analysis&lt;/h2&gt;
&lt;p&gt;The analysis reported in this study can be reproduced by following these steps:&lt;/p&gt;
&lt;h3 id=&#34;download-the-required-datasets&#34;&gt;Download the required datasets&lt;/h3&gt;
&lt;p&gt;The datasets used in the study are listed on &lt;a href=&#34;https://ppg-beats.readthedocs.io/en/latest/datasets/summary/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this page&lt;/a&gt;. Download each dataset in turn by following the instructions provided on each dataset&amp;rsquo;s page.&lt;/p&gt;
&lt;h3 id=&#34;install-the-ppg-beats-toolbox&#34;&gt;Install the PPG-beats toolbox&lt;/h3&gt;
&lt;p&gt;Install the &lt;strong&gt;PPG-beats&lt;/strong&gt; toolbox by following the instructions on &lt;a href=&#34;https://ppg-beats.readthedocs.io/en/latest/toolbox/getting_started/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;assess-the-performance-of-ppg-beat-detectors-across-all-the-datasets&#34;&gt;Assess the performance of PPG beat detectors across all the datasets&lt;/h3&gt;
&lt;p&gt;Use the &lt;code&gt;assess_multiple_datasets.m&lt;/code&gt; script (within &lt;strong&gt;PPG-beats&lt;/strong&gt;) to assess the performance of PPG beat detectors across all of the datasets. To do so:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Edit the &lt;code&gt;assess_multiple_datasets.m&lt;/code&gt; script:
&lt;ul&gt;
&lt;li&gt;Specify the path of the Matlab file for each dataset in the &lt;code&gt;specify_path_of_dataset_file&lt;/code&gt; function within the &lt;code&gt;assess_multiple_datasets.m&lt;/code&gt; script.&lt;/li&gt;
&lt;li&gt;Specify the folder in which to save results figures by modifying the &lt;code&gt;up.paths.plots_root_folder&lt;/code&gt; variable within the &lt;code&gt;setup_universal_params&lt;/code&gt; function within the &lt;code&gt;assess_multiple_datasets.m&lt;/code&gt; script.&lt;/li&gt;
&lt;li&gt;Specify the datasets to be analysed in the &lt;code&gt;setup_universal_params&lt;/code&gt; function within the &lt;code&gt;assess_multiple_datasets.m&lt;/code&gt; script:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;up.assessment_datasets = {&#39;capnobase&#39;, &#39;bidmc&#39;, &#39;mimic_train_all&#39;, &#39;mimic_test_all&#39;, &#39;wesad_meditation&#39;, &#39;wesad_amusement&#39;, &#39;wesad_baseline&#39;, &#39;wesad_stress&#39;, &#39;ppg_dalia_sitting&#39;, &#39;ppg_dalia_working&#39;, &#39;ppg_dalia_cycling&#39;, &#39;ppg_dalia_walking&#39;, &#39;ppg_dalia_lunch_break&#39;, &#39;ppg_dalia_car_driving&#39;, &#39;ppg_dalia_stair_climbing&#39;, &#39;ppg_dalia_table_soccer&#39;}; 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;up.comparison_datasets = {&amp;lsquo;mimic_B&amp;rsquo;, &amp;lsquo;mimic_W&amp;rsquo;, &amp;lsquo;mimic_test_a&amp;rsquo;, &amp;lsquo;mimic_test_n&amp;rsquo;, &amp;lsquo;mimic_non_af&amp;rsquo;, &amp;lsquo;mimic_af&amp;rsquo;};&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- Specify the beat detectors to be used in the `specify_options` function within the `assess_multiple_datasets.m` script:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;options.beat_detectors = {&amp;lsquo;SWT&amp;rsquo;, &amp;lsquo;ATmax&amp;rsquo;, &amp;lsquo;SPAR&amp;rsquo;, &amp;lsquo;IMS&amp;rsquo;, &amp;lsquo;AMPD&amp;rsquo;, &amp;lsquo;MSPTD&amp;rsquo;, &amp;lsquo;ABD&amp;rsquo;, &amp;lsquo;qppgfast&amp;rsquo;, &amp;lsquo;HeartPy&amp;rsquo;, &amp;lsquo;COppg&amp;rsquo;, &amp;lsquo;PPGPulses&amp;rsquo;, &amp;lsquo;ERMA&amp;rsquo;, &amp;lsquo;PWD&amp;rsquo;, &amp;lsquo;PDA&amp;rsquo;, &amp;lsquo;WFD&amp;rsquo;};&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2. Run the `assess_multiple_datasets.m` script, which will:
- Analyse each dataset in turn
- Generate results (in the command window) and results figures (saved in the specified folder)

### Generate additional figures

The additional figures in the manuscript can be generated as follows:
- **Fig. 1** (Detecting beats in the photoplethysmogram): - run the `create_ppg_beat_detection_fig.m` script.
- **Fig. 2** (Comparing PPG-derived beats with reference beats): - run the `make_plot_of_ecg_ppg_time_alignment.m` script.
- **Fig. 5** (PPG beat detection during different activities): - run the `make_plot_of_ppg_beat_detection_challenges.m` script.

---&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Respiratory rate algorithms for wearables</title>
      <link>https://peterhcharlton.github.io/project/rr-wearables/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/project/rr-wearables/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;The aim of the Respiratory Rate Estimation project is to develop and assess methods for automated respiratory rate (RR) monitoring. It consists of a series of studies of different algorithms for RR estimation from clinical data, complimented by the provision of publicly available datasets and resources.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=C3JPImVkouc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This video&lt;/a&gt; provides an introduction to the project.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Respiratory rate is a widely used indicator of health, used by clinicians in conjunction with other parameters to assess the health of patients in hospitals, clinics, and the community. For instance, all acutely-ill hospital patients have their respiratory rate measured every few hours to facilitate early detection of clinical deteriorations (deteriorations in health). However, respiratory rate is usually measured manually, by counting the number of breaths a patient takes in a specific period of time, such as a minute. This can potentially be time-consuming and inaccurate.&lt;/p&gt;
&lt;p&gt;An alternative solution could be provided by developing an automated, electronic method for measuring respiratory rate using a device. To this end a plethora of algorithms have been proposed to estimate respiratory rate from several physiological signals, such as the electrocardiogram, photoplethysmogram, accelerometry signal, impedance pneumography signal, and so on. These signals can be easily measured, and in some scenarios are already measured for other purposes. Consequently, a robust, practicable algorithm for estimating respiratory rate from these signals could potentially benefit patients and healthcare providers alike.&lt;/p&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;h3 id=&#34;understanding-the-state-of-the-art&#34;&gt;Understanding the state-of-the-art&lt;/h3&gt;
&lt;p&gt;A &lt;a href=&#34;https://peterhcharlton.github.io/publication/rr_review/&#34;&gt;literature review&lt;/a&gt; was conducted to understand the state-of-the-art on algorithms to estimate RR from the ECG and PPG. Briefly, we found that RR algorithms had been described in over 196 publications. We also found that previous studies assessing algorithm performance focused mostly on developing novel algorithms, rather than comparing algorithms. In addition, we found that the majority of previous studies of algorithm performance used data from young adults and healthy subjects, rather than assessing performance in our target setting of older, unhealthy adults.&lt;/p&gt;
&lt;p&gt;This helped refine our research questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How well do respiratory rate algorithms perform in the target setting?&lt;/li&gt;
&lt;li&gt;Which algorithm performs best?&lt;/li&gt;
&lt;li&gt;Is it clinically useful?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;developing-a-toolbox-of-algorithms&#34;&gt;Developing a toolbox of algorithms&lt;/h3&gt;
&lt;p&gt;We implemented many of the RR algorithms described in the literature (which are now available in the &lt;a href=&#34;#toolbox-of-rr-algorithms&#34;&gt;toolbox&lt;/a&gt; detailed below). We verified their performance on ideal, simulated data in &lt;a href=&#34;https://peterhcharlton.github.io/publication/rr_algs_assessment/&#34;&gt;this publication&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;assessment&#34;&gt;Assessment&lt;/h3&gt;
&lt;p&gt;The performance of RR algorithms was assessed on young, healthy volunteers in &lt;a href=&#34;https://peterhcharlton.github.io/publication/rr_algs_assessment/&#34;&gt;this publication&lt;/a&gt;, and on hospital patients in &lt;a href=&#34;https://peterhcharlton.github.io/publication/cont_resp_monitoring/&#34;&gt;this publication&lt;/a&gt;. Briefly, we found a wide variation in the performance of algorithms. Even the best algorithms can produce large errors, which would be clinically significant when compared to the normal RR range of 12-20 bpm.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://peterhcharlton.github.io/publication/resp_sig_extraction/&#34;&gt;this publication&lt;/a&gt; we investigated technical and physiological factors which influence the performance of algorithms. This allowed us to provide recommendations on how to monitor RR using wearables.&lt;/p&gt;
&lt;p&gt;The potential clinical utility of algorithms for detecting acute deteriorations in ambulatory hospital patients was assessed in &lt;a href=&#34;https://peterhcharlton.github.io/publication/cont_resp_monitoring/&#34;&gt;this publication&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;future-work&#34;&gt;Future work&lt;/h3&gt;
&lt;p&gt;In the future, we would like to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implement novel techniques designed to handle lower quality signals&lt;/li&gt;
&lt;li&gt;Assess the performance of algorithms in daily life&lt;/li&gt;
&lt;li&gt;Perform a comprehensive evaluation of algorithm performance across different settings&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;Please see the publications below for results arising from the project. In addition, &lt;a href=&#34;https://www.youtube.com/watch?v=qlt80ne0t-A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this video&lt;/a&gt; provides an overview of the work conducted to date.&lt;/p&gt;
&lt;h2 id=&#34;toolbox-of-rr-algorithms&#34;&gt;Toolbox of RR Algorithms&lt;/h2&gt;
&lt;p&gt;Research into respiratory rate algorithms has been hindered by a lack of open-source algorithms. Consequently, one aim of this project is to provide open-source algorithms to facilitate future research. As stated in the licence accompanying the source code, the algorithms are not intended to be fit for any purpose. Instead, they act as a platform from which researchers can develop algorithms.&lt;/p&gt;
&lt;p&gt;The following resources are provided:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/peterhcharlton/RRest/archive/master.zip&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Algorithm Source Code&lt;/a&gt;: The latest version of the toolbox of algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/peterhcharlton/RRest/wiki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;User Manual&lt;/a&gt;: A helpful resource for new users of the toolbox.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/peterhcharlton/RRest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github Repository&lt;/a&gt;: A repository of all versions of the toolbox, past and present.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Wearable photoplethysmography for health monitoring</title>
      <link>https://peterhcharlton.github.io/talk/wearable-photoplethysmography-for-health-monitoring/</link>
      <pubDate>Tue, 26 Apr 2022 13:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/talk/wearable-photoplethysmography-for-health-monitoring/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wearable photoplethysmography for health monitoring</title>
      <link>https://peterhcharlton.github.io/talk/wearable-photoplethysmography-for-health-monitoring/</link>
      <pubDate>Tue, 12 Apr 2022 12:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/talk/wearable-photoplethysmography-for-health-monitoring/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Developing software to monitor respiratory rate using wearable sensors</title>
      <link>https://peterhcharlton.github.io/talk/developing-software-to-monitor-respiratory-rate-using-wearable-sensors/</link>
      <pubDate>Fri, 08 Apr 2022 10:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/talk/developing-software-to-monitor-respiratory-rate-using-wearable-sensors/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &amp;ndash;&amp;gt;&lt;/p&gt;
&lt;!-- Click on the **Slides** button above to view the built-in slides feature. --&gt;
&lt;!--
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
</description>
    </item>
    
    <item>
      <title>Wearable photoplethysmography for cardiovascular monitoring</title>
      <link>https://peterhcharlton.github.io/publication/wearable_ppg_review/</link>
      <pubDate>Tue, 15 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/wearable_ppg_review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VascAgeNet Photoplethysmography Group</title>
      <link>https://peterhcharlton.github.io/post/vascagenet_ppg_group/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/post/vascagenet_ppg_group/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Vascular ageing is a natural process by which the function and structure of blood vessels degrade over time. It can manifest as elevated blood pressure, increased arterial stiffness, and atherosclerosis. Current approaches to assess vascular age have been found to be predictive of cardiovascular morbidity and mortality, but are often not convenient enough for widespread use.&lt;/p&gt;
&lt;p&gt;This group of European researchers is investigating the use of photoplethysmography to assess vascular age. Photoplethysmography is a non-invasive optical technique for measuring the arterial pulse wave, providing information on the state of the heart and blood vessels. The group is part of the wider &lt;a href=&#34;https://vascagenet.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VascAgeNet network&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;work-to-date&#34;&gt;Work to date&lt;/h2&gt;
&lt;p&gt;The group have co-authored several publications:&lt;/p&gt;
&lt;h3 id=&#34;group-papers&#34;&gt;Group papers&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/vascagenet_ppg_review&#34;&gt;Assessing hemodynamics from the photoplethysmogram to gain insights into vascular age: A review from VascAgeNet&lt;/a&gt;: &lt;em&gt;A review of techniques to assess vascular age from the photoplethysmogram. Co-authored by 16 researchers from 11 countries.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/best_practices_ppg/&#34;&gt;Establishing best practices in photoplethysmography signal acquisition and processing&lt;/a&gt;: &lt;em&gt;An editorial on whether it would be possible and beneficial to establish best practices for photoplethysmography signal acquisition and processing. Co-authored by 3 group members.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;collaborative-research&#34;&gt;Collaborative research&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/cinc2021_bp_estimation/&#34;&gt;Blood Pressure Estimation Based on Photoplethysmography: Finger versus Wrist&lt;/a&gt;: &lt;em&gt;Comparing blood pressure estimates obtained from finger and wrist sensors.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;collaborative-reviews&#34;&gt;Collaborative reviews&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_chapter/&#34;&gt;Wearable photoplethysmography devices&lt;/a&gt;: &lt;em&gt;A comprehensive overview of the state-of-the-art of wearable photoplethysmography devices.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_review&#34;&gt;Wearable photoplethysmography for cardiovascular monitoring&lt;/a&gt;: &lt;em&gt;A review of wearable photoplethysmgoraphy, considering the technology, signal processing, and clinical applications.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;invited-talks&#34;&gt;Invited Talks&lt;/h2&gt;
&lt;p&gt;The following speakers gave invited talks to the group in 2021:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kevin Kotzen&lt;/strong&gt;: &lt;em&gt;Benchmarking Photoplethysmography Peak Detection Algorithms Using the Electrocardiogram Signal as a Reference&lt;/em&gt;, 7 October 2021. &lt;a href=&#34;https://peterhcharlton.github.io/publication/vascagenet_ppg_review&#34;&gt;Accompanying paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Birute Paliakaite&lt;/strong&gt;: &lt;em&gt;Blood Pressure Estimation Based on Photoplethysmography: Finger versus Wrist&lt;/em&gt;, 28 October 2021. &lt;a href=&#34;https://peterhcharlton.github.io/publication/cinc21_bp_estimation/&#34;&gt;Accompanying paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wan-Hua Lin&lt;/strong&gt; (Shenzhen Institute of Advanced Technology, Chinese Academy of Science, China): &lt;em&gt;Investigating the physiological mechanisms of the photoplethysmogram features for blood pressure estimation&lt;/em&gt;, 18 November 2021. &lt;a href=&#34;https://doi.org/10.1088/1361-6579/ab7d78&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Accompanying paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Philip Aston&lt;/strong&gt; (National Physical Laboratory, UK): 9 December 2021.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In 2022 group members have given talks in a &lt;a href=&#34;https://peterhcharlton.github.io/post/ppg_webinars/&#34;&gt;public webinar series on Photoplethysmography&lt;/a&gt;, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;John Allen&lt;/strong&gt;: presented on &lt;em&gt;Further explorations in photoplethysmography for the detection of occlusive peripheral arterial disease&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Panicos Kyriacou&lt;/strong&gt;: presented on &lt;em&gt;Non-invasive optical monitoring of Intracranial Pressure in Traumatic Brain Injury patients&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Serena Zanelli&lt;/strong&gt;: will present on &lt;em&gt;Deep learning approach to detect signal quality from clinical to non-clinical PPG devices&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1109/EMBC46164.2021.9629640&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Accompanying paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;short-term-scientific-mission&#34;&gt;Short-Term Scientific Mission&lt;/h2&gt;
&lt;p&gt;Dr Peter Charlton spent 5 days at Kaunas University of Technology (KTU), hosted by Prof Vaidotas Marozas, Director of the Institute of Biomedical Engineering. During this STSM, Vaidotas, Peter and Birute Paliakaite worked with colleagues at KTU towards harmonising photoplethysmography-based techniques for the assessment of vascular ageing. This was funded by &lt;a href=&#34;https://vascagenet.eu/short-term-scientific-missions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VascAgeNet&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;group-members&#34;&gt;Group Members&lt;/h2&gt;
&lt;p&gt;The work of the group would not be possible without the hard work of its members, who include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Peter Charlton&lt;/a&gt; is a Biomedical Engineer specialising in signal processing techniques for the photoplethysmogram (PPG), including estimating respiratory rate and assessing vascular age from the PPG. He presently holds a British Heart Foundation Fellowship at the University of Cambridge.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=YtQF4uUAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Birute Paliakaite&lt;/a&gt; is a researcher specialising in PPG signal processing and modelling, and has made key contributions on acquiring haemodynamic parameters from wearables, and detecting and modelling arrhythmias in the PPG.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=IJ5MsM4AAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Kristjan Pilt&lt;/a&gt; has developed novel techniques to assess vascular age from the PPG in his research, and has demonstrated their potential clinical utility in diabetic patients.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.at/citations?user=pHHJAv4AAAAJ&amp;amp;hl=de&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Martin Bachler&lt;/a&gt; is a research engineer in the field of clinical diagnostics and therapy support, and specialises in biomedical signal analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://vascagenet.eu/what-are-you-working-on-serena-zanelli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Serena Zanelli&lt;/a&gt; develops machine learning and deep learning models to detect cardiovascular disease from PPG signals acquired by wearables, working in both academic and clinical settings.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://vascagenet.eu/what-are-you-working-on-dr-daniel-kulin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Daniel Kulin&lt;/a&gt; is a medical doctor, researcher and entrepreneur in the field of PPG-based pulse wave analysis and in the development of remote patient monitoring systems.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/citations?user=-GsW3HsAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof John Allen&lt;/a&gt; is a leading researcher in the field of photoplethysmography. He has worked on assessing vascular age from the PPG for approximately 30 years. He has strong experience on developing PPG-based techniques, and translating them towards clinical practice. His seminal review on photoplethysmography has been cited over 3,000 times.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Magid-Hallab&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Magid Hallab&lt;/a&gt; is a physician, inventor of pOpmetre, a device for PPG-based pulse wave velocity measurement, and CEO of Axelife, the company who sell the pOpmetre device.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.it/citations?user=rQqSulEAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Elisabetta Bianchini&lt;/a&gt; works in the field of ultrasound imaging and cardiovascular bioengineering, with strong interests in technology transfer.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.at/citations?user=gRActvYAAAAJ&amp;amp;hl=de&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Christopher Mayer&lt;/a&gt; conducts research in the field of biomedical signal processing, including simulation and pulse wave analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=w1KRD3gAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Dimitrios Terentes-Printzios&lt;/a&gt; is a Cardiologist with research interests in hypertension and microvascular dysfunction. He conducted his PhD on vascular ageing and has co-organised and large multicentre studies.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/verena-dittrich-1876a989/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Verena Dittrich&lt;/a&gt; is Co-Founder and CEO of Redwave Medical, a company specialising in algorithms for cardiovascular assessment.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=VP9nyHAAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Bernhard Hametner&lt;/a&gt; is a mathematician developing methods for pulse wave analysis, and is involved in the analysis of cardiovascular parameters obtained in clinical studies.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=Z_Fojr4AAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mr Dave Veerasingam&lt;/a&gt; is a Consultant Cardiothoracic Surgeon, and is involved in the cardiac Medtech industry. His research interests include the association between vascular ageing and target organ damage.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Dejan-Zikic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Dejan Zikic&lt;/a&gt; is an Associate Professor in Biophysics, with research interests including modelling pulse wave propagation and pulse wave analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.lt/citations?user=yQcWpoIAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Vaidotas Marozas&lt;/a&gt; is Director of the Biomedical Engineering Institute at Kaunas Institute of Technology, and has conducted research into PPG modelling, analysis, and acquisition using wearables.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking Photoplethysmography Peak Detection Algorithms Using the Electrocardiogram Signal as a Reference</title>
      <link>https://peterhcharlton.github.io/publication/cinc2021_beat_detection/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/cinc2021_beat_detection/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Blood Pressure Estimation Based on Photoplethysmography: Finger versus Wrist</title>
      <link>https://peterhcharlton.github.io/publication/cinc2021_bp_estimation/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/cinc2021_bp_estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The functionality of consumer wearables</title>
      <link>https://peterhcharlton.github.io/post/functionality_of_wearables/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/post/functionality_of_wearables/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;I recently had a look into the functionality of consumer wearables to understand the state-of-the-art. This post summarises the findings, and further details are provided in the following book chapter: &lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_chapter/&#34;&gt;Wearable Photoplethysmography Devices&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;functionality&#34;&gt;Functionality&lt;/h2&gt;
&lt;p&gt;The functionality of selected consumer wearables is summarised in the table below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Wearable&lt;/th&gt;
&lt;th&gt;Form factor&lt;/th&gt;
&lt;th&gt;HR&lt;/th&gt;
&lt;th&gt;irreg.&lt;/th&gt;
&lt;th&gt;SpO2&lt;/th&gt;
&lt;th&gt;RR&lt;/th&gt;
&lt;th&gt;BP&lt;/th&gt;
&lt;th&gt;sleep&lt;/th&gt;
&lt;th&gt;calories&lt;/th&gt;
&lt;th&gt;VO2 max&lt;/th&gt;
&lt;th&gt;ECG&lt;/th&gt;
&lt;th&gt;steps&lt;/th&gt;
&lt;th&gt;elevation&lt;/th&gt;
&lt;th&gt;temp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Apple Watch Series 6&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Withings Scanwatch&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Samsung Galaxy Watch3&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fitbit Sense&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Garmin Forerunner 945&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Amazfit GTR 2e&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Huawei Watch GT2 Pro (ECG)&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fossil Gen 5&lt;/td&gt;
&lt;td&gt;wrist watch&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WHOOP Strap 3.0&lt;/td&gt;
&lt;td&gt;wrist strap&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Biostrap Evo&lt;/td&gt;
&lt;td&gt;wrist band&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Oura Ring&lt;/td&gt;
&lt;td&gt;finger ring&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jabra Elite Sport&lt;/td&gt;
&lt;td&gt;ear buds&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bodytrak&lt;/td&gt;
&lt;td&gt;ear buds + case&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cosinuss Two&lt;/td&gt;
&lt;td&gt;ear wrap around&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Owlet Smart Sock Baby Monitor 3&lt;/td&gt;
&lt;td&gt;ankle sock&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AIO Sleeve 2.0&lt;/td&gt;
&lt;td&gt;arm sleeve&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Polar OH1 Sensor&lt;/td&gt;
&lt;td&gt;armband OR goggles&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://aktiia.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aktiia Bracelet&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;wrist band&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Defintions: irreg. - irregular pulse detection; RR - respiratory rate; BP - blood pressure; temp - temperature.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;p&gt;Adapted under &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY 4.0&lt;/a&gt; from:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Seshadri, D.R. et al., &amp;lsquo;Wearable sensors for COVID-19: a call to action to harness our digital infrastructure for remote patient monitoring and virtual assessments.&amp;rsquo; Front. Digit. Heal. 2020, 2, 1-11, DOI: &lt;a href=&#34;https://doi.org/10.3389/fdgth.2020.00008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.3389/fdgth.2020.00008&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Original source (reproduced under &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY 4.0&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P. H. Charlton, &amp;lsquo;Wearable sensor images.&amp;rsquo; Zenodo, 2021. DOI: &lt;a href=&#34;https://doi.org/10.5281/zenodo.798234&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.5281/zenodo.798234&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Version: 12 March 2021&lt;/p&gt;
&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;
&lt;p&gt;For further information on the state-of-the-art in wearable photoplethysmography devices, please see the following book chapter: &lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_chapter/&#34;&gt;Wearable Photoplethysmography Devices&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Photoplethysmography Textbook</title>
      <link>https://peterhcharlton.github.io/post/ppg_book/</link>
      <pubDate>Tue, 10 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/post/ppg_book/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This new textbook, titled &lt;em&gt;Photoplethysmography&lt;/em&gt;, is due to be published in late 2021. Several experts in the field have contributed to the textbook, which is intended to provide a comprehensive summary of the theory, principles and technology of photoplethysmography.&lt;/p&gt;
&lt;h2 id=&#34;sample-chapters&#34;&gt;Sample Chapters&lt;/h2&gt;
&lt;p&gt;The following sample chapters are available:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/ppg_sig_proc_chapter/&#34;&gt;Photoplethysmography signal processing and synthesis&lt;/a&gt;&lt;/strong&gt;: A comprehensive overview of signal processing techniques for the photoplethysmogram signal.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_chapter/&#34;&gt;Wearable photoplethysmography devices&lt;/a&gt;&lt;/strong&gt;: A comprehensive overview of the state-of-the-art of wearable photoplethysmography devices.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;link-to-published-version&#34;&gt;Link to Published Version&lt;/h2&gt;
&lt;p&gt;The published version of the textbook is available &lt;a href=&#34;https://www.elsevier.com/books/photoplethysmography/kyriacou/978-0-12-823374-0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, and can be previewed &lt;a href=&#34;https://www.google.co.uk/books/edition/_/d8wnEAAAQBAJ?gbpv=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. (Note that some of the images in the preview version are in black and white, whereas the sample chapters above contain full colour images.)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wearable photoplethysmography devices</title>
      <link>https://peterhcharlton.github.io/publication/wearable_ppg_chapter/</link>
      <pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/wearable_ppg_chapter/</guid>
      <description>&lt;h3 id=&#34;links-to-full-text&#34;&gt;Links to full text&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf&#34;&gt;Accepted manuscript&lt;/a&gt;&lt;/strong&gt;: The accepted version of the manuscript, freely available.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://doi.org/10.1016/B978-0-12-823374-0.00011-6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Published manuscript&lt;/a&gt;&lt;/strong&gt;: The published version, requiring access.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.google.co.uk/books/edition/_/d8wnEAAAQBAJ?gbpv=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Books preview&lt;/a&gt;&lt;/strong&gt;: This version is limited as the images are in black and white.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.elsevier.com/books/photoplethysmography/kyriacou/978-0-12-823374-0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The entire book&lt;/a&gt;&lt;/strong&gt;: The published version is available to purchase.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;further-details-of-the-textbook&#34;&gt;Further details of the textbook&lt;/h3&gt;
&lt;p&gt;Further details of the textbook are provided &lt;a href=&#34;https://peterhcharlton.github.io/post/ppg_book/&#34;&gt;here&lt;/a&gt;, including another freely available sample chapter.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using consumer devices for clinical assessment</title>
      <link>https://peterhcharlton.github.io/talk/using-consumer-devices-for-clinical-assessment/</link>
      <pubDate>Mon, 19 Jul 2021 16:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/talk/using-consumer-devices-for-clinical-assessment/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The &#39;Respiratory rate algorithms for wearables&#39; project</title>
      <link>https://peterhcharlton.github.io/talk/the-respiratory-rate-algorithms-for-wearables-project/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/talk/the-respiratory-rate-algorithms-for-wearables-project/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &amp;ndash;&amp;gt;&lt;/p&gt;
&lt;!-- Click on the **Slides** button above to view the built-in slides feature. --&gt;
&lt;!--
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
</description>
    </item>
    
    <item>
      <title>Realising the potential of wearables</title>
      <link>https://peterhcharlton.github.io/publication/realising_potential_wearables/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/realising_potential_wearables/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Realising the potential of wearables for health monitoring</title>
      <link>https://peterhcharlton.github.io/talk/realising-the-potential-of-wearables-for-health-monitoring/</link>
      <pubDate>Thu, 18 Mar 2021 11:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/talk/realising-the-potential-of-wearables-for-health-monitoring/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &amp;ndash;&amp;gt;&lt;/p&gt;
&lt;!-- Click on the **Slides** button above to view the built-in slides feature. --&gt;
&lt;!--
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
</description>
    </item>
    
    <item>
      <title>SAFER Wearables Study</title>
      <link>https://peterhcharlton.github.io/project/safer-wearables/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/project/safer-wearables/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The SAFER Wearables Study:&lt;/strong&gt; &lt;em&gt;A study of the acceptability and performance of wearables for atrial fibrillation screening in older adults&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This page provides details of the study and links to study resources:&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;strong&gt;Overview of the Study&lt;/strong&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;h1 id=&#34;overview-of-the-study&#34;&gt;Overview of the Study&lt;/h1&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Atrial fibrillation (AF) is an irregular heart rhythm which causes a five-fold increase in the risk of stroke. Approximately one in ten people aged over 70 have AF. If AF is recognised then the risk of stroke can be reduced by taking tablets regularly. AF can be difficult to recognise as it can occur without symptoms and only intermittently. Consequently, AF is not recognised in many people, meaning they live with an increased risk of stroke. Therefore, it is important to find ways to identify AF more reliably.&lt;/p&gt;
&lt;p&gt;Recently, wearable devices have been developed which could be useful for identifying AF. Several devices can monitor heart activity in daily life, including wristbands, smart watches and chest patch monitors. The aim of this study is to assess the acceptability and performance of wearables for use in AF screening in older adults.&lt;/p&gt;
&lt;figure  id=&#34;figure-wearable-devices-a-range-of-wearable-devices-could-potentially-be-used-in-af-screening&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://peterhcharlton.github.io/post/safer_wearables_testing/featured.png&#34; alt=&#34;**Wearable devices**: A range of wearable devices could potentially be used in AF screening.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Wearable devices&lt;/strong&gt;: A range of wearable devices could potentially be used in AF screening.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;aim&#34;&gt;Aim&lt;/h2&gt;
&lt;p&gt;The primary objective is to determine the feasibility of measuring inter-beat-intervals using a wristband.&lt;/p&gt;
&lt;p&gt;The secondary objectives are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;To determine the acceptability of wearables,&lt;/li&gt;
&lt;li&gt;To determine the acceptability of the screening approach,&lt;/li&gt;
&lt;li&gt;To assess the performance of wearables for acquiring signals,&lt;/li&gt;
&lt;li&gt;To assess the performance of signal processing algorithms,&lt;/li&gt;
&lt;li&gt;To assess the performance of wearables for AF screening.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;who-can-participate&#34;&gt;Who can participate?&lt;/h2&gt;
&lt;p&gt;Selected people who have previously participated in the &lt;a href=&#34;https://www.safer.phpc.cam.ac.uk/&#34;&gt;SAFER Programme&lt;/a&gt; can participate in this study. The Investigators (at the University of Cambridge) will invite previous SAFER Programme participants to also participate in this study, aiming to enrol 65 without AF, and 65 with AF.&lt;/p&gt;
&lt;h2 id=&#34;what-does-the-study-involve&#34;&gt;What does the study involve?&lt;/h2&gt;
&lt;p&gt;Participants will be asked to wear three devices for seven days: Two wristbands (like watches), and one chest patch (like a plaster). These devices will collect measurements of their heart&amp;rsquo;s activity. The Investigators will also ask participants to tell them how they found wearing the devices by completing a questionnaire. The Investigators will compare how participants found wearing each device, and how accurately each device identifies AF.&lt;/p&gt;
&lt;h2 id=&#34;further-information&#34;&gt;Further Information&lt;/h2&gt;
&lt;p&gt;Further information on the study can be found at ClinicalTrials.gov (&lt;a href=&#34;https://clinicaltrials.gov/ct2/show/NCT04715555&#34;&gt;NCT04715555&lt;/a&gt;).&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;&lt;strong&gt;Study Planning&lt;/strong&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;h1 id=&#34;study-planning&#34;&gt;Study Planning&lt;/h1&gt;
&lt;h2 id=&#34;planning&#34;&gt;Planning&lt;/h2&gt;
&lt;p&gt;Notebooks detailing the planning for the study are available &lt;a href=&#34;https://github.com/peterhcharlton/safer-wearables/tree/main/planning&#34;&gt;here&lt;/a&gt;. In particular, the following notebooks may be of interest:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nbviewer.org/github/peterhcharlton/safer-wearables/blob/main/planning/safer_wearables_planning.ipynb&#34;&gt;SAFER Wearables Planning notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;equipment-testing&#34;&gt;Equipment Testing&lt;/h2&gt;
&lt;p&gt;Details of equipment testing are provided in the following posts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/post/safer_wearables_testing&#34;&gt;Testing wearables - Part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://peterhcharlton.github.io/post/safer_wearables_testing2&#34;&gt;Testing wearables - Part 2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Equipment testing is ongoing.&lt;/p&gt;
&lt;h2 id=&#34;standard-operating-procedures-sops&#34;&gt;Standard Operating Procedures (SOPs)&lt;/h2&gt;
&lt;p&gt;SOPs providing fine detail on the practicalities of carrying out the study are available &lt;a href=&#34;https://peterhcharlton.github.io/info/safer_wearables/sops/sops.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;&lt;strong&gt;Study Methodology&lt;/strong&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;h1 id=&#34;study-methodology&#34;&gt;Study Methodology&lt;/h1&gt;
&lt;h2 id=&#34;ethics-approval&#34;&gt;Ethics Approval&lt;/h2&gt;
&lt;p&gt;Details of the ethical approvals for the study are available &lt;a href=&#34;https://peterhcharlton.github.io/info/safer_wearables/details/approvals&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;
&lt;p&gt;Study documentation will be made openly available in an online repository in the future.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Acquiring wearable photoplethysmography data in daily life: The PPG Diary Pilot Study</title>
      <link>https://peterhcharlton.github.io/publication/ppg_diary/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/ppg_diary/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Conducting a systematic review</title>
      <link>https://peterhcharlton.github.io/post/systematic_review/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/post/systematic_review/</guid>
      <description>&lt;p&gt;When looking for articles on a particular subject, search engines can quickly produce a wealth of information at our fingertips: 15,400 results in just 0.1 seconds in the search below. In this post I explore the challenge of using search engines to find as much useful literature as possible, whilst not spending all day (or in this case, several months) doing it!&lt;/p&gt;














&lt;figure  id=&#34;figure-a-quick-search-reveals-thousands-and-thousands-and-thousands-of-results&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;A quick search reveals thousands and thousands and thousands of results.&#34; srcset=&#34;
               /post/systematic_review/featured_hu7fd5934ada8eac26f64bcb39704ecc10_238125_aac4b19007ec4bc96aa7c3a35866a672.png 400w,
               /post/systematic_review/featured_hu7fd5934ada8eac26f64bcb39704ecc10_238125_ad4d8f8052d919057ef1045aa376753e.png 760w,
               /post/systematic_review/featured_hu7fd5934ada8eac26f64bcb39704ecc10_238125_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;https://peterhcharlton.github.io/post/systematic_review/featured_hu7fd5934ada8eac26f64bcb39704ecc10_238125_aac4b19007ec4bc96aa7c3a35866a672.png&#34;
               width=&#34;760&#34;
               height=&#34;393&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      A quick search reveals thousands and thousands and thousands of results.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;During my &lt;a href=&#34;https://theses.eurasip.org/theses/829/continuous-respiratory-rate-monitoring-to-detect/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PhD&lt;/a&gt; I spent many a happy hour looking through the literature on algorithms to estimate respiratory rate from two signals often measured by wearables: the photoplethysmogram and the electrocardiogram. I wanted to find the best algorithm out there, which I assumed meant trawling through every last bit of literature until I found it. In 2017 we published a &lt;a href=&#34;https://doi.org/10.1109/RBME.2017.2763681&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;systematic review&lt;/a&gt; of these algorithms, and two of the lessons I learnt stick with me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not all search engines are created equal&lt;/li&gt;
&lt;li&gt;One search engine just isn&amp;rsquo;t enough (but how many are?)&lt;/li&gt;
&lt;li&gt;You need lots of search terms (but if you&amp;rsquo;re not careful you&amp;rsquo;ll get lots of junk)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the rest of this post I provide insights into these two dilemmas, drawing on the results from our systematic review.&lt;/p&gt;
&lt;h2 id=&#34;not-all-search-engines-are-created-equal&#34;&gt;Not all search engines are created equal&lt;/h2&gt;
&lt;p&gt;In our review we used five search engines, and our own manual searching, to find the 196 publications included in the review. The five search engines returned vastly different proportions of the 196 publications that were eventually included:&lt;/p&gt;














&lt;figure  id=&#34;figure-the-coverage-of-the-five-search-engines-the-percentage-of-the-publications-which-were-included-in-the-review-returned-by-each-search-engine&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The coverage of the five search engines: the percentage of the publications which were included in the review returned by each search engine.&#34; srcset=&#34;
               /post/systematic_review/search_engine_coverage_hu0f2718ad2fdfbf44821fe0ba76762b20_52154_4c6331d09eb762fce451bfcdaa3d00ed.png 400w,
               /post/systematic_review/search_engine_coverage_hu0f2718ad2fdfbf44821fe0ba76762b20_52154_9be67b1800f73cfc1e8455ea3ab9e44a.png 760w,
               /post/systematic_review/search_engine_coverage_hu0f2718ad2fdfbf44821fe0ba76762b20_52154_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;https://peterhcharlton.github.io/post/systematic_review/search_engine_coverage_hu0f2718ad2fdfbf44821fe0ba76762b20_52154_4c6331d09eb762fce451bfcdaa3d00ed.png&#34;
               width=&#34;760&#34;
               height=&#34;380&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The coverage of the five search engines: the percentage of the publications which were included in the review returned by each search engine.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;At one end, Scopus returned 61% of the publications (119 out of the 196 included publications). At the other end, Science Direct returned only 10%.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Take home message:&lt;/em&gt; &lt;strong&gt;A single search engine probably won&amp;rsquo;t return all the results of interest.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You may also be interested in how much time it takes to download the results from each search engine. In our review we downloaded the results as text files from four of the search engines, and manually copied out the results for one search engine:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Search Engine&lt;/th&gt;
&lt;th&gt;Method used to download results&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Google Scholar&lt;/td&gt;
&lt;td&gt;Copied by hand as no convenient method was available to download results&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IEEE Xplore&lt;/td&gt;
&lt;td&gt;Downloaded as CSV (comma-separated values) file&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pubmed&lt;/td&gt;
&lt;td&gt;Downloaded as CSV (comma-separated values) file&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Science Direct&lt;/td&gt;
&lt;td&gt;Downloaded as .bib (Bibtex) file&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Scopus&lt;/td&gt;
&lt;td&gt;Downloaded as CSV (comma-separated values) file&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Take home message:&lt;/em&gt; &lt;strong&gt;Some search engines allow you to easily download the results, others don&amp;rsquo;t.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once you have your results, you then need to screen them to identify the relevant publications for inclusion in the review. This can be time-consuming, so ideally you wouldn&amp;rsquo;t want to have to screen too many publications for each one finally included. The number of publications we screened per relevant result also varied greatly between search engines:&lt;/p&gt;














&lt;figure  id=&#34;figure-the-number-of-publications-which-had-to-be-screened-to-obtain-each-relevant-result-for-each-search-engine&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The number of publications which had to be screened to obtain each relevant result, for each search engine.&#34; srcset=&#34;
               /post/systematic_review/number_screened_hua6bbd43f4693f9ea2c27e2d89257c8b2_52336_839c9237ee3e5ea34d14610377523dc4.png 400w,
               /post/systematic_review/number_screened_hua6bbd43f4693f9ea2c27e2d89257c8b2_52336_39d7367124be84a324b75945ab07033b.png 760w,
               /post/systematic_review/number_screened_hua6bbd43f4693f9ea2c27e2d89257c8b2_52336_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;https://peterhcharlton.github.io/post/systematic_review/number_screened_hua6bbd43f4693f9ea2c27e2d89257c8b2_52336_839c9237ee3e5ea34d14610377523dc4.png&#34;
               width=&#34;760&#34;
               height=&#34;380&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The number of publications which had to be screened to obtain each relevant result, for each search engine.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;Take home message:&lt;/em&gt; &lt;strong&gt;The time taken to screen results varies greatly between search engines.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you must use only one search engine, choose well, as their performance and ease of use differ greatly.&lt;/p&gt;
&lt;h2 id=&#34;one-search-engine-just-isnt-enough-but-how-many-are&#34;&gt;One search engine just isn&amp;rsquo;t enough (but how many are?)&lt;/h2&gt;
&lt;p&gt;The most comprehensive results came from Scopus, which found 119 out of the 196 publications, but if we&amp;rsquo;d only used that then we&amp;rsquo;d have missed nearly 40% of the articles we were looking for. So, one search engine just isn&amp;rsquo;t enough &amp;hellip;&lt;/p&gt;
&lt;p&gt;But how many are? Google Scholar returned a huge 383 potentially relevant results, which were copied down by hand (as they couldn&amp;rsquo;t be exported). In the end, only 14% of these were relevant (it took a while to find that out). At this rate, I wasn&amp;rsquo;t keen to add more search engines in to the mix. I looked back at how many results we would have obtained when using different numbers of search engines:&lt;/p&gt;














&lt;figure  id=&#34;figure-the-number-of-relevant-results-that-we-would-have-obtained-according-to-how-many-search-engines-were-used&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The number of relevant results that we would have obtained, according to how many search engines were used.&#34; srcset=&#34;
               /post/systematic_review/number_search_engines_hu83d8c0c3d1a06287842925adccfc7d7b_40453_cb733644c2edf9ea28374242acadbcb5.png 400w,
               /post/systematic_review/number_search_engines_hu83d8c0c3d1a06287842925adccfc7d7b_40453_4dfa8384654005b935c86b14db306e03.png 760w,
               /post/systematic_review/number_search_engines_hu83d8c0c3d1a06287842925adccfc7d7b_40453_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;https://peterhcharlton.github.io/post/systematic_review/number_search_engines_hu83d8c0c3d1a06287842925adccfc7d7b_40453_cb733644c2edf9ea28374242acadbcb5.png&#34;
               width=&#34;760&#34;
               height=&#34;380&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The number of relevant results that we would have obtained, according to how many search engines were used.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;So how many search engines are enough? In this search there was some benefit to increasing the number of search engines from one to four, but there was no benefit to using a fifth search engine. You&amp;rsquo;ll note that even all the search engines together returned only 150 out of 196 of the relevant publications included in the review: the remainder were identified manually (through web searching and reading the literature).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Take home message:&lt;/em&gt; &lt;strong&gt;It is advisable to use several search engines alongside manual searching.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;you-need-lots-of-search-terms-but-if-youre-not-careful-youll-get-lots-of-junk&#34;&gt;You need lots of search terms (but if you&amp;rsquo;re not careful you&amp;rsquo;ll get lots of junk)&lt;/h2&gt;
&lt;p&gt;In this review we aimed to obtain as many relevant results as possible from search engines, whilst minimising the amount of work required to screen the results. This meant choosing the search terms carefully. To do so we:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Performed an initial manual search:&lt;/strong&gt; this identified 90 relevant publications, which were mostly already known to us.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identified key themes from publication titles:&lt;/strong&gt; we reviewed the titles of these 90 publications to identify three key themes contained within the titles:
&lt;ul&gt;
&lt;li&gt;the process of respiration (e.g. &lt;em&gt;breathing&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;a mathematical process (e.g. &lt;em&gt;algorithm&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;the input signal (e.g. &lt;em&gt;photoplethysmogram&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identified keywords for each theme:&lt;/strong&gt; we identified keywords corresponding to each theme which occurred in at least 5% of titles. We found:
&lt;ul&gt;
&lt;li&gt;3 keywords for &amp;lsquo;&amp;lsquo;the process of respiration&amp;rsquo;&amp;rsquo;&lt;/li&gt;
&lt;li&gt;15 keywords for &amp;lsquo;&amp;lsquo;a mathematical process&amp;rsquo;&amp;rsquo;&lt;/li&gt;
&lt;li&gt;9 keywords for &amp;lsquo;&amp;lsquo;the input signal&amp;rsquo;&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eliminated keywords which did not add value:&lt;/strong&gt; we then looked at the proportion of publications which would have been identified had we insisted on the titles containing at least one keyword from each theme (76.7%). We then eliminated 10 keywords which, individually, did not add value to this search.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Finalised the search strategy:&lt;/strong&gt; The final search strategy, which encompassed 75.6% of the 90 manually identified publications was to insist on a publication containing at least one of the following keywords for each theme:&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Theme&lt;/th&gt;
&lt;th&gt;Keywords&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;respiration&lt;/td&gt;
&lt;td&gt;breathing, respiration, respiratory&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mathematical process&lt;/td&gt;
&lt;td&gt;derivation, derived, estimation, extraction, methods, rate, rates&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input signal&lt;/td&gt;
&lt;td&gt;ECG, electrocardiogram, photoplethysmogram, photoplethysmographic, photoplethysmography, PPG, pulse&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The end result was that our search identified 642 publications, 31% of which were deemed to be relevant, leading to the 196 publications which were finally included.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Take home message:&lt;/em&gt; &lt;strong&gt;Choose keywords carefully to avoid getting too much junk.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you are interested to find out more then you can read the review &lt;a href=&#34;https://doi.org/10.1109/RBME.2017.2763681&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgment&#34;&gt;Acknowledgment&lt;/h2&gt;
&lt;p&gt;Some of the content for this post was adapted under the &lt;a href=&#34;https://creativecommons.org/licenses/by/3.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY 3.0 Licence&lt;/a&gt; from:&lt;/p&gt;
&lt;p&gt;P. H. Charlton et al., &amp;lsquo;&#39;&lt;a href=&#34;https://doi.org/10.1109/RBME.2017.2763681&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Breathing rate estimation from the electrocardiogram and photoplethysmogram: a review&lt;/a&gt;,&amp;rsquo;&#39; &lt;em&gt;IEEE Rev. Biomed. Eng.&lt;/em&gt;, vol. 11, pp. 2-20, 2018.&lt;/p&gt;
&lt;h2 id=&#34;appendix-reproducing-the-results&#34;&gt;Appendix: reproducing the results&lt;/h2&gt;
&lt;p&gt;This appendix describes how to reproduce the results described and illustrated in this blog, and also the results presented in the &lt;a href=&#34;https://doi.org/10.1109/RBME.2017.2763681&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;review paper&lt;/a&gt;. &lt;em&gt;NB: You will need Matlab software to reproduce these results. The files required are available at: &lt;a href=&#34;https://doi.org/10.5281/zenodo.3741463&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.5281/zenodo.3741463&lt;/a&gt; .&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;optimising-the-search-strategy&#34;&gt;Optimising the search strategy&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;&lt;a href=&#34;https://zenodo.org/record/3741463/files/BRLitReviewSearchStrategy.m?download=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BRLitReviewSearchStrategy.m&lt;/a&gt;&lt;/em&gt; script reproduces the analysis used to optimise the search strategy, and generate the search strings.&lt;/p&gt;
&lt;h3 id=&#34;conducting-the-search&#34;&gt;Conducting the search&lt;/h3&gt;
&lt;p&gt;See the _&lt;a href=&#34;https://zenodo.org/record/3741463/files/BR_lit_review_suppl_mat.pdf?download=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BR_lit_review_suppl_mat.pdf&lt;/a&gt; file (Section S1.D) within the article&amp;rsquo;s supplementary material for details of how to reproduce the search.&lt;/p&gt;
&lt;h3 id=&#34;analysing-the-search-results&#34;&gt;Analysing the search results&lt;/h3&gt;
&lt;p&gt;Run &lt;em&gt;&lt;a href=&#34;https://zenodo.org/record/3741463/files/BRReviewAnalyses.m?download=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BRReviewAnalyses.m&lt;/a&gt;&lt;/em&gt; to obtain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The screening process results (as described in the &lt;em&gt;&lt;a href=&#34;https://zenodo.org/record/3741463/files/BR_lit_review_suppl_mat.pdf?download=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BR_lit_review_suppl_mat.pdf&lt;/a&gt;&lt;/em&gt; file (Section S1.C) within the article&amp;rsquo;s supplementary material).&lt;/li&gt;
&lt;li&gt;The plots in this blog&lt;/li&gt;
&lt;li&gt;The results of the analysis of individual articles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will also need the &lt;a href=&#34;https://zenodo.org/record/3741463/files/BRReviewScreeningResults.xlsx?download=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BRReviewScreeningResults.xlsx&lt;/a&gt; and &lt;a href=&#34;https://zenodo.org/record/3741463/files/BRReviewMethodologiesData.xlsx?download=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BRReviewMethodologiesData.xlsx&lt;/a&gt; files to reproduce these results.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Continuous respiratory rate monitoring to detect clinical deteriorations using wearable sensors</title>
      <link>https://peterhcharlton.github.io/publication/cont_resp_monitoring/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/cont_resp_monitoring/</guid>
      <description>&lt;h3 id=&#34;full-text&#34;&gt;Full text&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The published version is available &lt;a href=&#34;https://theses.eurasip.org/theses/829/continuous-respiratory-rate-monitoring-to-detect/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Extraction of respiratory signals from the electrocardiogram and photoplethysmogram: technical and physiological determinants</title>
      <link>https://peterhcharlton.github.io/publication/resp_sig_extraction/</link>
      <pubDate>Fri, 31 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/resp_sig_extraction/</guid>
      <description>&lt;h3 id=&#34;recognition&#34;&gt;Recognition&lt;/h3&gt;
&lt;p&gt;Featured in &lt;em&gt;Physiological Measurement&amp;rsquo;s&lt;/em&gt; &lt;a href=&#34;https://iopscience.iop.org/journal/0967-3334/page/Highlights_of_2017&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Highlights of 2017&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Making reproducible research as natural as breathing</title>
      <link>https://peterhcharlton.github.io/post/reproducible_research/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/post/reproducible_research/</guid>
      <description>&lt;p&gt;&lt;em&gt;Written by Peter Charlton whilst a PhD student at King&amp;rsquo;s College London, working on the Hospital of the Future (HotF) project. The overall aim of the HotF project is to provide early identification of hospital patients who are deteriorating. Peter&amp;rsquo;s work focuses on using wearable sensors to continuously assess patients&#39; health.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One of the key aims of the HotF project is to develop a technique to continuously monitor a patient&amp;rsquo;s &amp;ldquo;respiratory rate&amp;rdquo;: how often they breathe. Respiratory rate often changes early in the progression of a deterioration, giving advanced warning of a severe event such as a heart attack. However, it is currently measured by hand by counting the number of times a patient breathes in a set period of time. This approach is time-consuming, inaccurate, and only provides intermittent measurements. The alternative approach which I&amp;rsquo;m working on is to estimate respiratory rate from a small, unobtrusive, wearable sensor.&lt;/p&gt;
&lt;p&gt;Wearable sensors are currently routinely used to monitor heart rate and blood oxygenation levels. It turns out that the signals which provide these measurements are subtly influenced by respiration, as demonstrated below. If these subtle changes can be extracted reliably, then we could monitor respiratory rate &amp;ldquo;for free&amp;rdquo;, without the need for any additional sensors. This may provide all-important information on changes in a patient&amp;rsquo;s health, allowing clinicians to identify deteriorating patients earlier.&lt;/p&gt;














&lt;figure  id=&#34;figure-the-heart-rate-is-clearly-visible-in-this-signal-since-each-spike-corresponds-to-a-heart-beat-the-spikes-also-vary-in-height-with-each-of-the-four-breaths-these-subtle-changes-can-be-used-to-estimate-respiratory-rate&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The heart rate is clearly visible in this signal since each spike corresponds to a heart beat. The spikes also vary in height with each of the four breaths. These subtle changes can be used to estimate respiratory rate.&#34; srcset=&#34;
               /post/reproducible_research/featured_hu3e1360d471515a27bee2f20ca91ea161_3104_0ffb3831007b38b75c5015a9f4545527.png 400w,
               /post/reproducible_research/featured_hu3e1360d471515a27bee2f20ca91ea161_3104_3b97e3567e5d0068c43b9679cf0c80f8.png 760w,
               /post/reproducible_research/featured_hu3e1360d471515a27bee2f20ca91ea161_3104_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;https://peterhcharlton.github.io/post/reproducible_research/featured_hu3e1360d471515a27bee2f20ca91ea161_3104_0ffb3831007b38b75c5015a9f4545527.png&#34;
               width=&#34;760&#34;
               height=&#34;214&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The heart rate is clearly visible in this signal since each spike corresponds to a heart beat. The spikes also vary in height with each of the four breaths. These subtle changes can be used to estimate respiratory rate.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;So what&amp;rsquo;s all this got to do with reproducible research? Well, over the past few decades over 100 papers have been written describing methods for estimating respiratory rate electronically from signals that are already monitored by wearable sensors. If you read them (it takes a long time) then you find that hundreds of methods have been described. The key questions are: which method is the best, and is it good enough to use in clinical practice? Answering these questions can be a daunting task given how many different methods there are. Very few of the methods are publicly available, so to answer these questions you&amp;rsquo;d have to implement each of the methods yourself. Even once you have done this, you&amp;rsquo;d need to try them out on some data. Collecting this data is no easy task. Altogether, reproducing scientist&amp;rsquo;s previous work on this problem is quite difficult.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m hoping that this won&amp;rsquo;t be such a problem in the future. We have recently implemented many of the methods, collected a benchmark dataset on which to test the methods, and reported the results. All of this is publicly available. What&amp;rsquo;s more, you can &lt;a href=&#34;http://peterhcharlton.github.io/RRest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;download it all for free&lt;/a&gt;, from the methods, to the data, to the article describing the results. So in a few clicks you can catch up, reproduce our research, and start making progress yourself, even producing methods like this:&lt;/p&gt;














&lt;figure  id=&#34;figure-estimating-respiratory-rate-from-the-electrocardiogram-ecg-and-photoplethysmogram-ppg-signals-a-surrogate-respiratory-signal-can-be-extracted-from-each-of-the-ecg-and-ppg-signals-which-looks-similar-to-a-reference-respiratory-signal-resp-shown-above&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;**Estimating respiratory rate from the electrocardiogram (ECG) and photoplethysmogram (PPG) signals:** A surrogate respiratory signal can be extracted from each of the ECG and PPG signals, which looks similar to a reference respiratory signal (Resp), shown above.&#34;
           src=&#34;https://peterhcharlton.github.io/post/reproducible_research/petercharlton_resp_video_gif_red.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Estimating respiratory rate from the electrocardiogram (ECG) and photoplethysmogram (PPG) signals:&lt;/strong&gt; A surrogate respiratory signal can be extracted from each of the ECG and PPG signals, which looks similar to a reference respiratory signal (Resp), shown above.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Well, nearly &amp;hellip; I&amp;rsquo;ve written a &lt;a href=&#34;http://peterhcharlton.github.io/RRest/waveform_analysis.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutorial&lt;/a&gt; on the methods, which is due to be published in a textbook soon. This work can be reproduced exactly. Since then we have extended the range of publicly available resources by adding more methods, and the new benchmark dataset. This most recent work can&amp;rsquo;t be reproduced exactly since we had to make a few changes before making it publicly available. I intend to make future work on this topic fully reproducible so that researchers can build on our work. Who knows, perhaps this will contribute towards earlier identification of deteriorating patients in the future.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgment&#34;&gt;Acknowledgment&lt;/h2&gt;
&lt;p&gt;Originally published &lt;a href=&#34;https://kingsimaging.wordpress.com/2016/05/11/making-reproducible-research-as-natural-as-breathing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Probabilistic estimation of respiratory rate from wearable sensors</title>
      <link>https://peterhcharlton.github.io/publication/pimentel-2015-a/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://peterhcharlton.github.io/publication/pimentel-2015-a/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
